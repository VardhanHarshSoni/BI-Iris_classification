{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.datasets import load_iris\n\n# Load the dataset\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\ndf['target'] = iris.target\ndf['target_names'] = df['target'].apply(lambda x: iris.target_names[x])\n\n# Explore the dataset\nprint(df.head())\nprint(df.describe())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-26T04:10:44.472894Z","iopub.execute_input":"2024-06-26T04:10:44.473266Z","iopub.status.idle":"2024-06-26T04:10:46.839587Z","shell.execute_reply.started":"2024-06-26T04:10:44.473233Z","shell.execute_reply":"2024-06-26T04:10:46.838540Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n0                5.1               3.5                1.4               0.2   \n1                4.9               3.0                1.4               0.2   \n2                4.7               3.2                1.3               0.2   \n3                4.6               3.1                1.5               0.2   \n4                5.0               3.6                1.4               0.2   \n\n   target target_names  \n0       0       setosa  \n1       0       setosa  \n2       0       setosa  \n3       0       setosa  \n4       0       setosa  \n       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\ncount         150.000000        150.000000         150.000000   \nmean            5.843333          3.057333           3.758000   \nstd             0.828066          0.435866           1.765298   \nmin             4.300000          2.000000           1.000000   \n25%             5.100000          2.800000           1.600000   \n50%             5.800000          3.000000           4.350000   \n75%             6.400000          3.300000           5.100000   \nmax             7.900000          4.400000           6.900000   \n\n       petal width (cm)      target  \ncount        150.000000  150.000000  \nmean           1.199333    1.000000  \nstd            0.762238    0.819232  \nmin            0.100000    0.000000  \n25%            0.300000    0.000000  \n50%            1.300000    1.000000  \n75%            1.800000    2.000000  \nmax            2.500000    2.000000  \n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Features and labels\nX = df.drop(['target', 'target_names'], axis=1)\ny = df['target']\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:11:10.286434Z","iopub.execute_input":"2024-06-26T04:11:10.287256Z","iopub.status.idle":"2024-06-26T04:11:10.408351Z","shell.execute_reply.started":"2024-06-26T04:11:10.287210Z","shell.execute_reply":"2024-06-26T04:11:10.407200Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Create and train the model\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Make predictions\ny_pred = rf_model.predict(X_test)\n\n# Evaluate the model\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(classification_report(y_test, y_pred, target_names=iris.target_names))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:11:10.562610Z","iopub.execute_input":"2024-06-26T04:11:10.563349Z","iopub.status.idle":"2024-06-26T04:11:11.099430Z","shell.execute_reply.started":"2024-06-26T04:11:10.563315Z","shell.execute_reply":"2024-06-26T04:11:11.098319Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Accuracy: 1.0\n              precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        10\n  versicolor       1.00      1.00      1.00         9\n   virginica       1.00      1.00      1.00        11\n\n    accuracy                           1.00        30\n   macro avg       1.00      1.00      1.00        30\nweighted avg       1.00      1.00      1.00        30\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Define the model\nmodel = Sequential([\n    Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n    Dense(10, activation='relu'),\n    Dense(3, activation='softmax')  # 3 classes for iris dataset\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=2)\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy}\")\n\n# Make predictions\ny_pred_tf = model.predict(X_test)\ny_pred_classes = y_pred_tf.argmax(axis=1)\n\n# Evaluate the TensorFlow model\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_classes)}\")\nprint(classification_report(y_test, y_pred_classes, target_names=iris.target_names))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:11:11.101429Z","iopub.execute_input":"2024-06-26T04:11:11.101897Z","iopub.status.idle":"2024-06-26T04:11:32.149975Z","shell.execute_reply.started":"2024-06-26T04:11:11.101860Z","shell.execute_reply":"2024-06-26T04:11:32.148740Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-06-26 04:11:13.216452: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-26 04:11:13.216614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-26 04:11:13.370379: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"3/3 - 1s - 441ms/step - accuracy: 0.3542 - loss: 2.0505 - val_accuracy: 0.2917 - val_loss: 1.8094\nEpoch 2/100\n3/3 - 0s - 16ms/step - accuracy: 0.3542 - loss: 1.9550 - val_accuracy: 0.2917 - val_loss: 1.7089\nEpoch 3/100\n3/3 - 0s - 16ms/step - accuracy: 0.3542 - loss: 1.8754 - val_accuracy: 0.2917 - val_loss: 1.6138\nEpoch 4/100\n3/3 - 0s - 17ms/step - accuracy: 0.3542 - loss: 1.7968 - val_accuracy: 0.2917 - val_loss: 1.5255\nEpoch 5/100\n3/3 - 0s - 16ms/step - accuracy: 0.3542 - loss: 1.7222 - val_accuracy: 0.2917 - val_loss: 1.4484\nEpoch 6/100\n3/3 - 0s - 16ms/step - accuracy: 0.3542 - loss: 1.6549 - val_accuracy: 0.2917 - val_loss: 1.3822\nEpoch 7/100\n3/3 - 0s - 16ms/step - accuracy: 0.3542 - loss: 1.6003 - val_accuracy: 0.2917 - val_loss: 1.3258\nEpoch 8/100\n3/3 - 0s - 16ms/step - accuracy: 0.3542 - loss: 1.5456 - val_accuracy: 0.2917 - val_loss: 1.2779\nEpoch 9/100\n3/3 - 0s - 17ms/step - accuracy: 0.3542 - loss: 1.5010 - val_accuracy: 0.2917 - val_loss: 1.2349\nEpoch 10/100\n3/3 - 0s - 17ms/step - accuracy: 0.3542 - loss: 1.4570 - val_accuracy: 0.2917 - val_loss: 1.1963\nEpoch 11/100\n3/3 - 0s - 16ms/step - accuracy: 0.3542 - loss: 1.4184 - val_accuracy: 0.2917 - val_loss: 1.1620\nEpoch 12/100\n3/3 - 0s - 16ms/step - accuracy: 0.3542 - loss: 1.3845 - val_accuracy: 0.2917 - val_loss: 1.1315\nEpoch 13/100\n3/3 - 0s - 17ms/step - accuracy: 0.3854 - loss: 1.3482 - val_accuracy: 0.3750 - val_loss: 1.1050\nEpoch 14/100\n3/3 - 0s - 17ms/step - accuracy: 0.3958 - loss: 1.3245 - val_accuracy: 0.5417 - val_loss: 1.0800\nEpoch 15/100\n3/3 - 0s - 17ms/step - accuracy: 0.4583 - loss: 1.2971 - val_accuracy: 0.7500 - val_loss: 1.0588\nEpoch 16/100\n3/3 - 0s - 17ms/step - accuracy: 0.4375 - loss: 1.2751 - val_accuracy: 0.6250 - val_loss: 1.0399\nEpoch 17/100\n3/3 - 0s - 20ms/step - accuracy: 0.3646 - loss: 1.2511 - val_accuracy: 0.5000 - val_loss: 1.0235\nEpoch 18/100\n3/3 - 0s - 17ms/step - accuracy: 0.3125 - loss: 1.2321 - val_accuracy: 0.5000 - val_loss: 1.0092\nEpoch 19/100\n3/3 - 0s - 17ms/step - accuracy: 0.2917 - loss: 1.2117 - val_accuracy: 0.5000 - val_loss: 0.9962\nEpoch 20/100\n3/3 - 0s - 17ms/step - accuracy: 0.2917 - loss: 1.1947 - val_accuracy: 0.5000 - val_loss: 0.9845\nEpoch 21/100\n3/3 - 0s - 17ms/step - accuracy: 0.2917 - loss: 1.1778 - val_accuracy: 0.5000 - val_loss: 0.9734\nEpoch 22/100\n3/3 - 0s - 17ms/step - accuracy: 0.2812 - loss: 1.1618 - val_accuracy: 0.5000 - val_loss: 0.9634\nEpoch 23/100\n3/3 - 0s - 17ms/step - accuracy: 0.2812 - loss: 1.1470 - val_accuracy: 0.5000 - val_loss: 0.9537\nEpoch 24/100\n3/3 - 0s - 16ms/step - accuracy: 0.2812 - loss: 1.1320 - val_accuracy: 0.5000 - val_loss: 0.9443\nEpoch 25/100\n3/3 - 0s - 16ms/step - accuracy: 0.2812 - loss: 1.1164 - val_accuracy: 0.5000 - val_loss: 0.9353\nEpoch 26/100\n3/3 - 0s - 17ms/step - accuracy: 0.2812 - loss: 1.1019 - val_accuracy: 0.5000 - val_loss: 0.9268\nEpoch 27/100\n3/3 - 0s - 17ms/step - accuracy: 0.2812 - loss: 1.0873 - val_accuracy: 0.5000 - val_loss: 0.9185\nEpoch 28/100\n3/3 - 0s - 18ms/step - accuracy: 0.2812 - loss: 1.0724 - val_accuracy: 0.5000 - val_loss: 0.9106\nEpoch 29/100\n3/3 - 0s - 18ms/step - accuracy: 0.2812 - loss: 1.0584 - val_accuracy: 0.5000 - val_loss: 0.9031\nEpoch 30/100\n3/3 - 0s - 20ms/step - accuracy: 0.2812 - loss: 1.0448 - val_accuracy: 0.5000 - val_loss: 0.8942\nEpoch 31/100\n3/3 - 0s - 21ms/step - accuracy: 0.2812 - loss: 1.0287 - val_accuracy: 0.5000 - val_loss: 0.8823\nEpoch 32/100\n3/3 - 0s - 20ms/step - accuracy: 0.2812 - loss: 1.0140 - val_accuracy: 0.5000 - val_loss: 0.8704\nEpoch 33/100\n3/3 - 0s - 18ms/step - accuracy: 0.2812 - loss: 0.9947 - val_accuracy: 0.5000 - val_loss: 0.8589\nEpoch 34/100\n3/3 - 0s - 18ms/step - accuracy: 0.2812 - loss: 0.9747 - val_accuracy: 0.5000 - val_loss: 0.8479\nEpoch 35/100\n3/3 - 0s - 17ms/step - accuracy: 0.2812 - loss: 0.9564 - val_accuracy: 0.5417 - val_loss: 0.8364\nEpoch 36/100\n3/3 - 0s - 17ms/step - accuracy: 0.3125 - loss: 0.9383 - val_accuracy: 0.5833 - val_loss: 0.8263\nEpoch 37/100\n3/3 - 0s - 18ms/step - accuracy: 0.4688 - loss: 0.9207 - val_accuracy: 0.6250 - val_loss: 0.8187\nEpoch 38/100\n3/3 - 0s - 17ms/step - accuracy: 0.5208 - loss: 0.9038 - val_accuracy: 0.6667 - val_loss: 0.8113\nEpoch 39/100\n3/3 - 0s - 19ms/step - accuracy: 0.5833 - loss: 0.8929 - val_accuracy: 0.7083 - val_loss: 0.8049\nEpoch 40/100\n3/3 - 0s - 17ms/step - accuracy: 0.6146 - loss: 0.8851 - val_accuracy: 0.7083 - val_loss: 0.7998\nEpoch 41/100\n3/3 - 0s - 20ms/step - accuracy: 0.6250 - loss: 0.8792 - val_accuracy: 0.7083 - val_loss: 0.7961\nEpoch 42/100\n3/3 - 0s - 19ms/step - accuracy: 0.6458 - loss: 0.8748 - val_accuracy: 0.7083 - val_loss: 0.7935\nEpoch 43/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8706 - val_accuracy: 0.7083 - val_loss: 0.7913\nEpoch 44/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.8669 - val_accuracy: 0.7083 - val_loss: 0.7892\nEpoch 45/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.8638 - val_accuracy: 0.7083 - val_loss: 0.7875\nEpoch 46/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8601 - val_accuracy: 0.7083 - val_loss: 0.7853\nEpoch 47/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8568 - val_accuracy: 0.7083 - val_loss: 0.7829\nEpoch 48/100\n3/3 - 0s - 18ms/step - accuracy: 0.6354 - loss: 0.8540 - val_accuracy: 0.7083 - val_loss: 0.7813\nEpoch 49/100\n3/3 - 0s - 19ms/step - accuracy: 0.6458 - loss: 0.8506 - val_accuracy: 0.7083 - val_loss: 0.7792\nEpoch 50/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.8477 - val_accuracy: 0.7083 - val_loss: 0.7771\nEpoch 51/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8448 - val_accuracy: 0.7083 - val_loss: 0.7748\nEpoch 52/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8420 - val_accuracy: 0.7083 - val_loss: 0.7732\nEpoch 53/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.8392 - val_accuracy: 0.7083 - val_loss: 0.7717\nEpoch 54/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8364 - val_accuracy: 0.7083 - val_loss: 0.7698\nEpoch 55/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.8337 - val_accuracy: 0.7083 - val_loss: 0.7680\nEpoch 56/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.8311 - val_accuracy: 0.7083 - val_loss: 0.7662\nEpoch 57/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.8285 - val_accuracy: 0.7083 - val_loss: 0.7644\nEpoch 58/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8262 - val_accuracy: 0.7083 - val_loss: 0.7631\nEpoch 59/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8236 - val_accuracy: 0.7083 - val_loss: 0.7615\nEpoch 60/100\n3/3 - 0s - 20ms/step - accuracy: 0.6458 - loss: 0.8212 - val_accuracy: 0.7083 - val_loss: 0.7596\nEpoch 61/100\n3/3 - 0s - 21ms/step - accuracy: 0.6458 - loss: 0.8188 - val_accuracy: 0.7083 - val_loss: 0.7578\nEpoch 62/100\n3/3 - 0s - 20ms/step - accuracy: 0.6458 - loss: 0.8167 - val_accuracy: 0.7083 - val_loss: 0.7563\nEpoch 63/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8145 - val_accuracy: 0.7083 - val_loss: 0.7547\nEpoch 64/100\n3/3 - 0s - 20ms/step - accuracy: 0.6458 - loss: 0.8124 - val_accuracy: 0.7083 - val_loss: 0.7534\nEpoch 65/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.8102 - val_accuracy: 0.7083 - val_loss: 0.7517\nEpoch 66/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8081 - val_accuracy: 0.7083 - val_loss: 0.7497\nEpoch 67/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8061 - val_accuracy: 0.7083 - val_loss: 0.7479\nEpoch 68/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8042 - val_accuracy: 0.7083 - val_loss: 0.7455\nEpoch 69/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.8021 - val_accuracy: 0.7083 - val_loss: 0.7445\nEpoch 70/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.8002 - val_accuracy: 0.7083 - val_loss: 0.7434\nEpoch 71/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.7983 - val_accuracy: 0.7083 - val_loss: 0.7423\nEpoch 72/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.7964 - val_accuracy: 0.7083 - val_loss: 0.7416\nEpoch 73/100\n3/3 - 0s - 19ms/step - accuracy: 0.6458 - loss: 0.7945 - val_accuracy: 0.7083 - val_loss: 0.7398\nEpoch 74/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.7925 - val_accuracy: 0.7083 - val_loss: 0.7389\nEpoch 75/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.7908 - val_accuracy: 0.7083 - val_loss: 0.7370\nEpoch 76/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.7888 - val_accuracy: 0.7083 - val_loss: 0.7361\nEpoch 77/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.7871 - val_accuracy: 0.7083 - val_loss: 0.7351\nEpoch 78/100\n3/3 - 0s - 18ms/step - accuracy: 0.6458 - loss: 0.7854 - val_accuracy: 0.7083 - val_loss: 0.7344\nEpoch 79/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7837 - val_accuracy: 0.7083 - val_loss: 0.7324\nEpoch 80/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7820 - val_accuracy: 0.7083 - val_loss: 0.7308\nEpoch 81/100\n3/3 - 0s - 17ms/step - accuracy: 0.6458 - loss: 0.7803 - val_accuracy: 0.7083 - val_loss: 0.7289\nEpoch 82/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7785 - val_accuracy: 0.7083 - val_loss: 0.7281\nEpoch 83/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7770 - val_accuracy: 0.7083 - val_loss: 0.7269\nEpoch 84/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7753 - val_accuracy: 0.7083 - val_loss: 0.7265\nEpoch 85/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7736 - val_accuracy: 0.7083 - val_loss: 0.7254\nEpoch 86/100\n3/3 - 0s - 16ms/step - accuracy: 0.6562 - loss: 0.7720 - val_accuracy: 0.7083 - val_loss: 0.7239\nEpoch 87/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7705 - val_accuracy: 0.7083 - val_loss: 0.7226\nEpoch 88/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7689 - val_accuracy: 0.7083 - val_loss: 0.7212\nEpoch 89/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7674 - val_accuracy: 0.7083 - val_loss: 0.7191\nEpoch 90/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7658 - val_accuracy: 0.7083 - val_loss: 0.7176\nEpoch 91/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7642 - val_accuracy: 0.7083 - val_loss: 0.7163\nEpoch 92/100\n3/3 - 0s - 16ms/step - accuracy: 0.6562 - loss: 0.7629 - val_accuracy: 0.7083 - val_loss: 0.7158\nEpoch 93/100\n3/3 - 0s - 16ms/step - accuracy: 0.6562 - loss: 0.7614 - val_accuracy: 0.7083 - val_loss: 0.7151\nEpoch 94/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7599 - val_accuracy: 0.7083 - val_loss: 0.7133\nEpoch 95/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7585 - val_accuracy: 0.7083 - val_loss: 0.7113\nEpoch 96/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7570 - val_accuracy: 0.7083 - val_loss: 0.7104\nEpoch 97/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7555 - val_accuracy: 0.7083 - val_loss: 0.7097\nEpoch 98/100\n3/3 - 0s - 16ms/step - accuracy: 0.6562 - loss: 0.7541 - val_accuracy: 0.7083 - val_loss: 0.7086\nEpoch 99/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7527 - val_accuracy: 0.7083 - val_loss: 0.7082\nEpoch 100/100\n3/3 - 0s - 17ms/step - accuracy: 0.6562 - loss: 0.7512 - val_accuracy: 0.7083 - val_loss: 0.7071\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7000 - loss: 0.7334\nTest Accuracy: 0.699999988079071\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\nAccuracy: 0.7\n              precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        10\n  versicolor       0.00      0.00      0.00         9\n   virginica       0.55      1.00      0.71        11\n\n    accuracy                           0.70        30\n   macro avg       0.52      0.67      0.57        30\nweighted avg       0.54      0.70      0.59        30\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}